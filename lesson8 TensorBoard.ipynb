{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tf-nightly-2.0-preview\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "def create_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 18s 301us/sample - loss: 0.2209 - accuracy: 0.9348 - val_loss: 0.1026 - val_accuracy: 0.9695\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 18s 297us/sample - loss: 0.0959 - accuracy: 0.9698 - val_loss: 0.0720 - val_accuracy: 0.9769\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 11s 190us/sample - loss: 0.0678 - accuracy: 0.9788 - val_loss: 0.0777 - val_accuracy: 0.9742\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 12s 192us/sample - loss: 0.0525 - accuracy: 0.9831 - val_loss: 0.0744 - val_accuracy: 0.9770\n",
      "Epoch 5/5\n",
      "27296/60000 [============>.................] - ETA: 5s - loss: 0.0435 - accuracy: 0.9861"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "E0928 11:22:33.378501 140736299017024 ultratb.py:149] Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/arseniperchik/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-8c6b59a77ce0>\", line 13, in <module>\n",
      "    callbacks=[tensorboard_callback])\n",
      "  File \"/Users/arseniperchik/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 766, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"/Users/arseniperchik/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 333, in fit\n",
      "    total_epochs=epochs)\n",
      "  File \"/Users/arseniperchik/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 123, in run_one_epoch\n",
      "    batch_outs = execution_function(iterator)\n",
      "  File \"/Users/arseniperchik/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 86, in execution_function\n",
      "    distributed_function(input_fn))\n",
      "  File \"/Users/arseniperchik/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 540, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/Users/arseniperchik/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 570, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"/Users/arseniperchik/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2295, in __call__\n",
      "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
      "  File \"/Users/arseniperchik/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1556, in _filtered_call\n",
      "    self.captured_inputs)\n",
      "  File \"/Users/arseniperchik/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1637, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"/Users/arseniperchik/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 497, in call\n",
      "    ctx=ctx)\n",
      "  File \"/Users/arseniperchik/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\", line 61, in quick_execute\n",
      "    num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/arseniperchik/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/arseniperchik/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/arseniperchik/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/arseniperchik/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/arseniperchik/anaconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/arseniperchik/anaconda3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/arseniperchik/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/arseniperchik/anaconda3/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/Users/arseniperchik/anaconda3/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/Users/arseniperchik/anaconda3/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/Users/arseniperchik/anaconda3/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=5, \n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 15293), started 0:04:33 ago. (Use '!kill 15293' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1aa1620c2eca6964\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1aa1620c2eca6964\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0928 12:16:02.347087 140736299017024 _import_c_extension.py:41] This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-15d90d555476a632\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-15d90d555476a632\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6008;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# select random images and their target indices\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# helper function\n",
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# select random images and their target indices\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. gets the probability predictions in a test_size x num_classes Tensor\n",
    "# 2. gets the preds in a test_size Tensor\n",
    "# takes ~10 seconds to run\n",
    "class_probs = []\n",
    "class_preds = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "        _, class_preds_batch = torch.max(output, 1)\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_preds.append(class_preds_batch)\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_preds = torch.cat(class_preds)\n",
    "\n",
    "# helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_preds, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    '''\n",
    "    tensorboard_preds = test_preds == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_preds,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "    writer.close()\n",
    "\n",
    "# plot all the pr curves\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
